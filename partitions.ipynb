{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbbf4f02-8ee4-46e3-b02a-89ee4a58102f",
   "metadata": {},
   "source": [
    "In PySpark, you don't \"assign\" a fixed size to a partition like a hard memory limit. Instead, you influence the size of partitions by configuring Spark properties or by repartitioning your data based on a target count.\n",
    "\n",
    "Depending on whether you are **reading data**, **shuffling data** (during joins/grouping), or **writing data**, you use different methods to control partition size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc86a5f-bc7a-4ead-b481-061e585a20f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PartitionSizeControl\") \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"67108864\") \\\n",
    "    # Set to 64MB (64 * 1024 * 1024 bytes)\n",
    "    .getOrCreate()\n",
    "\n",
    "# Now, any read operation will try to split files into 64MB chunks\n",
    "df = spark.read.parquet(\"path/to/large_data\")\n",
    "print(f\"Number of partitions: {df.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc2ef9-9bfe-43cd-96b3-0059f8ac4aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Controlling Size During Shuffles (Joins/Aggregations)\n",
    "When you perform an operation that shuffles data (like a groupBy or join), Spark defaults to 200 partitions. If your data is 200 GB, each partition would be 1 GB (too large). If it's 200 MB, each would be 1 MB (too small)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
