{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf36f3d8-5942-4d83-9f81-ac12a8f16a37",
   "metadata": {},
   "source": [
    "1. Basic Databricks Interview Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e1799-3af8-4312-a92c-94fd3287c323",
   "metadata": {},
   "source": [
    "1. What is Databricks? Explain its key components.\n",
    "2. What is a cluster in Databricks? What are the different cluster types?\n",
    "3. What is the difference between a job cluster and an all-purpose cluster?\n",
    "4. What is the Databricks Workspace?\n",
    "5. What are notebooks in Databricks and what languages can they run?\n",
    "6. What is DBFS (Databricks File System)?\n",
    "7. How do you mount Azure Data Lake or AWS S3 in Databricks?\n",
    "8. What is Auto Loader in Databricks?\n",
    "9. What are widgets in Databricks notebooks?\n",
    "10. How do you schedule a Databricks notebook as a job?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdf6a4-cbae-4b08-835e-8f3e11712e02",
   "metadata": {},
   "source": [
    "2. Intermediate Databricks Interview Questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693cdf72-f899-4838-9086-a339272466ca",
   "metadata": {},
   "source": [
    "11. Explain the advantages of Delta Lake.\n",
    "12. What problem does Delta Lake solve?\n",
    "13. What are the Delta Lake features: ACID, time travel, schema enforcement, schema evolution?\n",
    "14. How does schema enforcement work in Delta Lake?\n",
    "15. What is the difference between MERGE and UPDATE in Delta?\n",
    "16. What is OPTIMIZE and ZORDER in Databricks?\n",
    "17. What is the small files problem in Delta tables?\n",
    "18. What is the purpose of VACUUM in Delta?\n",
    "19. Explain COPY INTO. When do you use it?\n",
    "20. What is Databricks Runtime (DBR)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5acf5-57c3-4afd-94a0-fcc88fd059f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Databricks SQL / Spark Interview Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcdb12d-56b2-4519-802e-60bd742e1cab",
   "metadata": {},
   "source": [
    "21. What is the difference between Spark DataFrame and Pandas DataFrame?\n",
    "22. What is Catalyst Optimizer and Tungsten?\n",
    "23. Explain narrow vs wide transformations in Spark.\n",
    "24. How do you handle skew in Spark?\n",
    "25. What causes shuffle in Spark?\n",
    "26. How do you reduce shuffle in Spark applications?\n",
    "27. What is broadcast join? When should you use it?\n",
    "28. What is AQE (Adaptive Query Execution)?\n",
    "29. What are Spark UDF, pandas UDF, and SQL functions?\n",
    "30. What is checkpointing vs. caching in Spark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b99b3-9262-4423-a09b-de69f582d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Databricks Lakehouse & Architecture Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1e74f-297f-4be3-915d-40e0a2f7d06f",
   "metadata": {},
   "source": [
    "31. What is the Databricks Lakehouse Platform?\n",
    "32. How does the Lakehouse differ from a traditional data warehouse?\n",
    "33. What is Unity Catalog?\n",
    "34. How do you secure data using Unity Catalog?\n",
    "35. What is the difference between a catalog, schema, and table in UC?\n",
    "36. What is the medallion architecture (Bronze, Silver, Gold)?\n",
    "37. How do you design a Delta Live Tables pipeline?\n",
    "38. What is serverless SQL warehouse?\n",
    "39. What are DBU charges?\n",
    "40. Explain cluster autoscaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d077c49-d833-4234-859a-32f1e9c522c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Real-Time & Streaming Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8cccfb-579a-4b30-9000-379e31c57e3b",
   "metadata": {},
   "source": [
    "41. What is Structured Streaming?\n",
    "42. What is Auto Loader and how is it different from readStream?\n",
    "43. What are checkpoints and triggers in streaming?\n",
    "44. How do you perform stream-to-stream and stream-to-batch join?\n",
    "45. How do you guarantee exactly-once processing in Databricks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1a26e-4c24-466c-9e33-8b1f7e0f6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Delta Lake Deep-Dive Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e8f9c0-955a-4596-91aa-788577f75f39",
   "metadata": {},
   "source": [
    "46. What is a Delta transaction log? Explain _delta_log.\n",
    "47. What is an OPTIMIZE with ZORDER?\n",
    "48. What is change data feed (CDF) in Delta Lake?\n",
    "49. How does Delta Lake handle late-arriving data?\n",
    "50. What happens internally when you run a MERGE INTO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c265c-5ca6-4a8e-a1ed-c9a8c9e59af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Databricks Security & Governance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1876b8d8-9abb-4527-98da-6ef1d1a29d53",
   "metadata": {},
   "source": [
    "51. How do you use cluster policies?\n",
    "52. How does Unity Catalog enforce permission inheritance?\n",
    "53. How do you audit data access in Databricks?\n",
    "54. What is Credential Passthrough / IAM roles?\n",
    "55. How do you secure PII data in Databricks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b76cb-63ba-44a8-b3d2-9cb15caf1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Databricks Performance & Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a8005-c487-42c1-8283-a0628b4b8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "56. How do you handle slow Spark jobs in Databricks?\n",
    "57. How do you identify shuffle spill or skew in the Spark UI?\n",
    "58. What are the best practices to optimize Delta tables?\n",
    "59. Describe file compaction strategy in Silver layer.\n",
    "60. How do you split large Bronze → Silver → Gold loads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e341be5-fd22-4b2d-8c8a-a480c84501da",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Scenario-Based Databricks Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd7f83-1266-44d6-a4c8-e0f962ff4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "66. Your Delta table has lots of small files. How do you fix it?\n",
    "67. A MERGE operation is running slow. What steps do you take?\n",
    "68. Your Silver table is showing corrupted records. How do you handle them?\n",
    "69. Your stream stopped due to schema mismatch. How do you fix it?\n",
    "70. How do you enforce data quality rules in Databricks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ae96c-331c-4bf1-9516-6989393c8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BONUS — Common HR + Behavioral Databricks Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd0253-4450-4b64-b9b2-9658755fb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "71. How did you use Databricks in your last project?\n",
    "72. What part of Databricks do you use the most?\n",
    "73. What’s the biggest optimization you did in Databricks?\n",
    "74. Explain a time you debugging a slow Spark job.\n",
    "75. Describe a Databricks architecture you designed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
